An RL agent models its world as an MDP, without knowing its transition and reward functions. In episodic learning, an *episode* is when the agent starts from an initial state and continues to take actions until it reaches a *terminal* state. These actions return rewards, which are then used to build up policies.

## Passive RL

